---
layout: post
title: Kafka Overview
date: 2020-12-28 01:26:23 +0900
category: Kafka
---

# Overview

- 데이터를 빠르게 수집할수록 조직의 대응력은 민첩해진다.
- 적은 노력으로 핵심 비즈니스에 집중하는 것이 가능하다.

---

### 메세지 발행 / 구독 (Publish / Subscribe)

- Kafka의 중요한 개념인 Publish / Subscribe

- 해당 시스템에서는 데이터를 발행자가 직접 구독자에게 보내지 않는다.
    - 발행자가 메세지를 구분해서 발행/구독 시스템에 전송하면, 구독자가 특정 부류의 메세지를 구독할 수 있게 해준다.
    - 발행된 메세지를 저장하고 중계하는 역할은 Broker가 수행한다.

- 초기의 발행/구독 시스템
    - 간단한 메세지 큐/ 프로세스간 통신 채널을 갖는 형태로 시작
    - 대쉬보드에서 다양한 기능을 하는 서버들이 추가되고, 각 front-end들 끼리 연결된다면?
    - 엄청나게 복잡한 Architecture가 생성
    - *모든 어플리케이션들의 메트릭을 하나의 어플리케이션이 수신하고, 하나의 서버로 제공한다면?*

- 개별적인 메세지 큐 시스템
    - 각 어플리케이션들이 다양한 Publish/Subscribe 시스템과 연결되어 있을 수도 있다.
    - 하지만 이 경우에도, 많은 기능이 중복된다.
    - 다른 종류의 메세지를 처리하려면 새로운 시스템을 추가해야하는 문제점도 존재한다.

### Kafka

- kafka
    - 위의 문제들을 해결하기 위해서 설립된 메세지 발행/구독 시스템
    - Distributed Commit Log와 Distributed Streaming Platform 이라고 한다.
    - 파일 시스템 / 데이터베이스의 커밋 로그는 시스템의 상태를 일관성있게 유지할 수 있도록 모든 트랜잭션을 기록한다.
        - Kafka또한 이와 유사하게 데이터를 지속해서 저장하고 읽을 수 있다.
    - 시스탬 장애에 대비하고 확장에 따른 성능 저하를 방지하기 위해 데이터가 분산 처리 될 수 있다.

- Message와 Batch
    1. Message
        - Data의 기본 단위를 Message라고 한다.
        - 데이터베이스의 Row와 Record에 비유 될 수 있다.
        - Kafka의 Message는 Byte 배열의 데이터로 간주하기 때문에, 특정 형식이나 의미를 갖지 않는다.
        - Key 라는 메타데이터가 포함될 수 있다.
            - Key 또한 바이트 배열이고 특별한 의미가 없다.
        - Message 배열은 Topic 으로 분류된 Partition에 수록된다.
            - Data를 수록할 Partition을 결정하기 위해 일관된 해시 값으로 키를 생성
                - 같은 key 값을 갖는 메세지는 항상 같은 Partition에 수록
    2. Batch
        - 효율성을 위해서 여러 개의 메세지를 모아 Batch 형태로 Partition에 수록한다.
            - Network로부터 매번 메세지를 받아서 처리하는 데 따른 부담 감소
        - Latency와 Throughput 간의 트레이드 오프가 생길 수 있다.
            - Batch 크기 ↑
            - 단위 시간당 처리하는 메세지 ↑
            - 메세지 전송 시간 ↑
        - 데이터 압축을 적용하여 효율적인 데이터 전송 및 저장 제공

- Schema
    - kafka는 메세지를 단순한 바이트 배열로 처리하지만, 내용을 이해하기 쉽도록 메세지의 구조를 나타내는 스키마를 사용 할 수 있다.
    - 스키마로 여러 형식 사용 가능
        - Javascript Object Notation (JSON)
        - Extensible Markup Language (XML)
            - 위의 두 가지는 강력한 데이터 타입에 대한 지원이 부족하고, 스키마 버전 간의 호환성이 떨어짐
        - Apache Avro
            - Hadoop을 위해 개발된 직렬화 프레임워크
            - 데이터를 직렬화하는 형식 제공
            - 메세지와 별개로 스키마 유지 및 관리
                - 때문에 스키마가 변경되더라도 Application 코드 수정 X
            - 강력한 데이터 타입 지원
            - 스키마 신/구버전 간 호환성

    - kafka 에서는 일관된 데이터 형식이 중요하다.
        - 쓰기와 읽기 작업을 분리해서 할 수 있기 때문
            - 만약 두가지가 합쳐져 있다면, 구버전 신버전의 데이터 형식을 병행 처리하기 위해서 메세지 구독 어플리케이션이 먼저 업데이트 되어야 함
            - 이후 메세지 발행 어플리케이션도 함께 업데이트 되어야 한다.
        - 하지만 카프카는 잘 정의된 스키마를 공유 Repository에 저장하여 사용할 수 있으므로 App 변경 없이 메세지를 처리할 수 있다.

- Topic과 Partition
    - Kafka의 메세지는 Topic으로 분류된다.
    - Topic
        - File System의 폴더 혹은 DB의 테이블과 유사한 개념
        - 하나의 Topic은 여러개의 Partition으로 구성
    - Partition
        - Commit Log 관점에서는 하나의 파티션이 하나의 로그
        - 메세지는 Partition에 추가된다.
        - 추가되는 메세지는 각 파티션의 끝에 수록
        - 각 파티션은 서로 다른 서버에 분산될 수 있다. (하나의 Topic이 여러 서버에 수평적으로 확장될 수 있음)
    - Stream
        - 대부분의 스트림은 파티션의 개수와 관계없이 하나의 토픽 데이터로 간주
        - Producer 에서 Consumer로 이동되는 연속적인 데이터

- Producer와 Consumer
    - Client는 시스템의 사용자이다
    - Producer와 Consumer 두가지가 존재
    - Producer
        - 새로운 Message를 생성
        - 메세지가 어떤 파티션에 수록되는지 관여하지 않는다.
        - 프로듀서가 특정 파티션에 메세지를 직접 쓰는 경우도 있기는 하다.
            - Message Key와 Partitioner 사용
            - Partitioner는 Key의 해시 값을 생성하고, 그것을 특정 파티션에 대응시켜 저장된 키를 갖는 메세지가 항상 같은 파티션에 수록되도록 해줌
        - 커스텀 파티셔너를 갖고 다른 규칙에 따라 메세지가 파티션에 대응되게 할 수도 있다.
    - Consumer
        - 메세지를 읽음
        - 하나 이상의 Topic을 구독하여 메세지가 생성된 순서로 읽는다.
        - 메세지의 Offset을 유지하여 읽는 메세지의 위치를 알 수 있다.
            - Metadata인 offset은 지속적으로 증가하는 정숫값이며, 메세지가 생성될 때 마다 Kafka가 추가해준다.
            - 파티션에 수록된 각 메세지는 고유한 오프셋을 갖는다.
        - Zookeeper나 카프카에서는 각 파티션에서 마지막에 읽은 메세지의 오프셋을 저장하고 있다.
            - Consumer가 메세지 읽기를 중단했다가 다시 시작하더라도 그 다음 메세지부터 읽기 가능
        - Consumer Group의 멤버로 동작한다.
            - 하나 이상의 Consumer로 구성되어, 한 Topic을 소비하기 위해서 같은 그룹의 Consumer가 함께 동작한다.
            - 한 Topic의 각 파티션은 하나의 Consumer만 소비할 수 있다.
            - 특정 Partition에 대응되는 것을 Partition Ownership 이라고 한다.
    - 이런 방법을 통해서 다량의 메세지를 갖는 토픽을 소비하기 위해 컨슈머를 수평적으로 확장할 수 있다.
    - 컨슈머가 자신의 파티션 메세지를 읽는데 실패하더라도 같은 그룹의 다른 컨슈머가 파티션 소유권을 재조정 받고, 대신 읽을 수 있다.

- Broker와 Cluster
    - Broker
        - 하나의 Kafka Server
        - Producer로부터 메세지를 수신하고 offset을 지정한 뒤 해당 메세지를 디스크에 저장
        - Consumer의 Partition 읽기 요청에 응답하고 Disk에 수록된 메세지 전송
        - 하나의 브로커는 초당 수천 개의 Topic 과 수백만 개의 Message 처리 (H/W 성능에 따라 달라짐)
    - Cluster
        - Broker는 Cluster의 일부로 동작하도록 설계
        - 여러 개의 Broker가 하나의 Cluster에 포함될 수 있다.
        - 그중 하나는 자동으로 선정되는 Cluster Controller의 기능 수행
        - Cluster Controller
            - 같은 Cluster 내 Broker에게 담당 Partition 할당
            - Broker들이 정상 동작하는지 모니터링하는 관리 기능
        - 각 파티션은 클러스터의 한 브로커가 소유한다.
        - Partition Leader
            - Partition을 소유한 브로커
        - 같은 Partition이 여러 Broker에 지정될 수도 있다.
            - 이 때에는 해당 Partition이 복제(replication) 된다.
            - 이 경우 해당 Partition의 메세지는 중복으로 저장되지만, 관련 Broker에 장애 발생시 다른 Broker가 소유권을 인계받아서 해당 Partition 처리
        - 각 Partition을 사용하는 모든 Consumer / Producer는 Partition Leader에 연결해야 한다.
    - Retention
        - 일정 기간동안 메세지를 보존하는 것
        - Kafka Broker는 기본적으로 Topic의 보존 설정을 하게 되어있다.
        - 일정 기간 동안 (혹은 일정 Topic 크기가 될 때 까지) 메세지를 보존
        - 한도 값에 도달하면 최소한의 데이터가 유지되도록 만료 메세지들이 삭제된다.
        - Topic들만 보존되도록 보존 설정을 다르게 지정하는 것도 가능하다.
            - 지속적인 메세지 유지가 필요한 Topic은 7일 동안
            - Application 성능 관련 메트릭은 수시간 동안만 보관
        - Topic은 log compacted 설정으로 구성 될 수도 있다.
            - 같은 Key를 갖는 메세지들은 가장 최신 것만 보존
            - 마지막으로 변경된 것이 중요한 로그 데이터에 유용
- **Multiple Cluster**  // 다시 볼 것
    - Kafka가 많이 설치되어서 사용될 때, Multiple Cluster를 고려한 장점
        - 데이터 타입에 따라 구분해서 처리 가능
        - 보안 요구사항 분리 가능
        - 재해 복구 대비 (다중 데이터 센터 유지)
    - 온라인 Application은 사용자의 처리 결과를 양쪽  모두에서 사용
    - Kafka Cluster의 복제 메커니즘은 단일 클러스터에서만 동작하도록 설계
    - MirrorMaker
        - Kafka의 컨슈머/프로듀서
        - 각 미러메이커는 큐로 상호 연결 되어있다.
        - 하나의 카프카 클러스터에서 소비된 메세지를 다른 클러스터에서도 사용할 수 있도록 생성해준다.
    - 두 개의 로컬 클러스터에서 aggregate cluster로 메세지를 모은 후 다른 데이터 센터로 복사


### Kafka를 사용하는 이유

- 다중 프로듀서
    - 여러 클라이언트가 많은 토픽을 사용하거나 같은 토픽을 사용해도 무리없이 많은 프로듀서의 메세지 처리 가능
        - ex). 여러 microservice를 통해 서비스를 제공하는 사이트에서, 모든 microservice가 같은 형식으로 작성한 page view를 하나의 토픽으로 갖음
        - 컨슈머는 그 사이트의 모든 application page view를 하나의 토픽으로 가짐
        - 이후 모든 page view를 하나의 스트림으로 받을 수 있음.
- 다중 컨슈머
    - 많은 Consumer가 상호 간섭 없이 어떤 메세지 스트림도 읽을 수 있도록 함
